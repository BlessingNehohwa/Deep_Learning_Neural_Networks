# Deep-Learning-Neural-Networks
This repository shows my journey into study of deep learning and neural network (Machine Learning)
### DEEP LEARNING INTRODUCTION
**Blessing Nehohwa**

A machine learning algorithm is like a black box that we feed input data and it delivers an output.

### The ingredients from making an Algorithm

- **Data :**
  Readily available historical data
 
- **Model :**
  We need a model the simplest mpodel we can train is a linear model
  stepping upon linear model. <br>Deep machine learning lets us create complicated  non-linear models- these usally fit the data much better than a simple linear model
  <br>It all boils down to optimising this function.
  <br>If our model is measuring the prediction error of the model we would want to minimize this error, minimise the objective function
  
- **Objective Function:**
  Is the Measure used to evaluate how well the model's outputs match the desired correct values.
  <br> These are generally split into Loss Functions and Reward Functions.
  <br> **Loss Functions** are also called Cost Functions , the lower the loss function the higher the accuracy.
  <br> The higher the **reward function** of the the higher the model's level of accuracy.
  <br> Loss functions are the most common function dealt with in real life.
  <br>Making sure that the output of the model is as close to reality as possible.
  <br> It estimates how correct the mode's outputs are on average
  
  
  **[Deep Learning Introduction Tutorial](https://github.com/BlessingNehohwa/Deep-Learning-Neural-Networks/blob/main/Deep%20Learning%20Tutorial.ipynb
).**
   
